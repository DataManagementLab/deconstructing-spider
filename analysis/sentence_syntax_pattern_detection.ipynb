{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Syntax Pattern Detection on Sentence Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import stanza\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup WordNet & Stopword List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "\n",
    "stopwords_en = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class ChangedBy(Enum):\n",
    "    DB_TABLE = 1\n",
    "    DB_COLUMN = 2\n",
    "    DB_VAL = 3\n",
    "    NER = 4\n",
    "    NUM = 5\n",
    "    SYNONYM = 6\n",
    "\n",
    "\n",
    "TABLE_NAME = '{TABLE}'\n",
    "COLUMN_NAME = '{COLUMN}'\n",
    "COLUMN_PARTIAL_NAME = '{COLUMN_PART}'\n",
    "DB_VALUE = '{VALUE}'\n",
    "NUMERICAL = '{NUMBER}'\n",
    "NAMED_ENTITY = '{NE}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify Spider database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "db_name = 'party_people'\n",
    "spider_directory = 'spider_data'\n",
    "db_directory = f'{spider_directory}/database/{db_name}'\n",
    "schema_file = f'{db_directory}/schema.sql'\n",
    "db_file = f'{db_directory}/{db_name}.sqlite'\n",
    "data_file = f'{spider_directory}/train_spider.json'\n",
    "tables_file = f'{spider_directory}/tables.json'\n",
    "export_trees_file = f'{spider_directory}/patterns.{db_name}.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: Load schema information from SQL file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_schema(db_id, tables_file_path):\n",
    "    \"\"\"\n",
    "    Load schema information from tables.json\n",
    "\n",
    "    :param db_id: database\n",
    "    :type db_id: str\n",
    "    :param tables_file_path: path to tables.json\n",
    "    :type tables_file_path: str\n",
    "    :return: db schema information, set of table names, set of column names\n",
    "    :rtype: Dict[Str, Any], set[str], set[str]\n",
    "    \"\"\"\n",
    "    with open(tables_file_path, \"r\") as tables_json:\n",
    "        dbs = json.load(tables_json)\n",
    "        for db_schema in dbs:\n",
    "            if db_schema[\"db_id\"] == db_id:\n",
    "                column_names = set(t[1].lower() for t in db_schema[\"column_names\"])\n",
    "                column_names.update(t[1].lower() for t in db_schema[\"column_names_original\"])\n",
    "                column_partial_names = set()\n",
    "                for column_name in column_names:\n",
    "                    column_partial_names.update(t for t in column_name.split() if not t in stopwords_en)\n",
    "                return db_schema, set(db_schema['table_names']), column_names, column_partial_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: Load database values from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_db_values(schema_file_path):\n",
    "    \"\"\"\n",
    "    Load all database values from file that are not stopwords\n",
    "\n",
    "    :param schema_file_path: data base schema definition file\n",
    "    :type schema_file_path: str\n",
    "    :return: All values of the selected database\n",
    "    :rtype: Set[Any]\n",
    "    \"\"\"\n",
    "    db_values = set()\n",
    "    with open(schema_file_path, 'r') as schema_file:\n",
    "        for line in schema_file.readlines():\n",
    "            if line.startswith(\"INSERT INTO\"):\n",
    "                # Get values part of insert string but without the surrounding blanks, brackets and the semicolon\n",
    "                values_raw = line.split(\"VALUES\")[-1][2:-3]\n",
    "                db_values.update(v for v in json.loads(f'[{values_raw}]') if not v in stopwords_en)\n",
    "\n",
    "    return db_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load DB Schema & values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "db_schema, db_tables, db_colums, db_partial_columns = load_schema(db_name, tables_file)\n",
    "print(db_schema)\n",
    "print(db_tables)\n",
    "print(db_colums)\n",
    "db_values = load_db_values(schema_file)\n",
    "print(db_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: Load NL-SQL pairs for given Spider database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_db_data(db, db_data_file):\n",
    "    \"\"\"\n",
    "    Load all data (NL-SQL) entries for the selected database\n",
    "\n",
    "    :param db: database\n",
    "    :type db: str\n",
    "    :param db_data_file: path of file containing NL-SQL entries\n",
    "    :type db_data_file: str\n",
    "    :return: NL-SQL-Entries\n",
    "    :rtype: List[Dict]\n",
    "    \"\"\"\n",
    "    with open(db_data_file, \"r\") as train_json:\n",
    "        return [entry for entry in json.load(train_json) if entry[\"db_id\"] == db]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load NL-SQL pairs for DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = load_db_data(db_name, data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stanza.download('en') # download English model\n",
    "nlp = stanza.Pipeline('en') # initialize English neural pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data structures for parse tree container and processed token list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ParseTree:\n",
    "    def __init__(self, orginal_nl_query, original_sql_query, tokens, raw_parsed):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "\n",
    "        :param orginal_nl_query: original NL query\n",
    "        :type orginal_nl_query: str\n",
    "        :param original_sql_query: original SQL query\n",
    "        :type original_sql_query: str\n",
    "        :param tokens: list of tokens\n",
    "        :type tokens: List[Token]\n",
    "        :param raw_parsed: raw stanza sentence parse\n",
    "        :type raw_parsed: stanza.Sentence\n",
    "        \"\"\"\n",
    "        self.orginal_nl_query = orginal_nl_query\n",
    "        self.original_sql_query = original_sql_query\n",
    "        self.tokens = tokens\n",
    "        self.ents = raw_parsed.ents\n",
    "        self.raw_parsed = raw_parsed\n",
    "        self.log = []\n",
    "\n",
    "    def unchanged(self):\n",
    "        \"\"\"\n",
    "        Get all unchanged tokens\n",
    "\n",
    "        :return: all not-yet changed tokens of this tree\n",
    "        :rtype: Generator[Token]\n",
    "        \"\"\"\n",
    "        return (token for token in self.tokens if not token.changed)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{'|'.join(str(t) for t in self.tokens)}\"\n",
    "\n",
    "\n",
    "class Token:\n",
    "    NUM_UNKNOWN = 0\n",
    "    NUM_SINGULAR = 1\n",
    "    NUM_PLURAL = 2\n",
    "\n",
    "    def __init__(self, parsed_token, is_compound=False, ent=None):\n",
    "        self.text = parsed_token.text\n",
    "        self.original_text = \"ERROR. TEXT WAS CHANGED WITHOUT USING CHANGE METHOD\"\n",
    "        self.text_lower = self.text.lower()\n",
    "        self.changed = False\n",
    "        self.changed_by = ''\n",
    "        self.properties = parsed_token\n",
    "        self.is_compound = is_compound\n",
    "        self.properties_list = [self.properties]\n",
    "        self.ent = ent\n",
    "        if parsed_token.feats is not None:\n",
    "            self.features = parsed_token.feats.split(\"|\")\n",
    "        else:\n",
    "            self.features = []\n",
    "        if \"Number=Sing\" in self.features:\n",
    "            self.num = self.NUM_SINGULAR\n",
    "        elif \"Number=Plur\" in self.features:\n",
    "            self.num = self.NUM_PLURAL\n",
    "        else:\n",
    "            self.num = self.NUM_UNKNOWN\n",
    "\n",
    "    def change(self, new_text, by):\n",
    "        \"\"\"\n",
    "        Change token\n",
    "\n",
    "        :param new_text: what to replace with\n",
    "        :type new_text: str\n",
    "        :param by: what pipeline part changed\n",
    "        :type by: str\n",
    "        \"\"\"\n",
    "        self.original_text = self.text\n",
    "        self.text = new_text\n",
    "        self.text_lower = self.text.lower()\n",
    "        self.changed = True\n",
    "        self.changed_by = by\n",
    "\n",
    "    def add_compound_component(self, parsed_token):\n",
    "        self.text += f\" {parsed_token.text}\"\n",
    "        self.text_lower = self.text.lower()\n",
    "        self.properties_list.append(parsed_token)\n",
    "\n",
    "    def __str__(self):\n",
    "        if self.changed:\n",
    "            return f\"{self.text} [{self.original_text}]\"\n",
    "        return self.text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: Generate Parse Tree incl. Provenance for given NL-SQL pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_parse_tree(nl_sql):\n",
    "    \"\"\"\n",
    "    Generated parsed form of given nl-sql entry\n",
    "\n",
    "    :param nl_sql: data entry containing a NL query\n",
    "    :type nl_sql: Dict[Str, Any]\n",
    "    :return: parse tree\n",
    "    :rtype: ParseTree\n",
    "    \"\"\"\n",
    "    # Parse and return parsed form of first sentence (there should always be only one)\n",
    "    parsed = nlp(nl_sql[\"question\"]).sentences[0]\n",
    "\n",
    "    ents_by_start = {e.start_char: e for e in parsed.ents}\n",
    "\n",
    "    # Create a list of words (and make sure compounds are recombined)\n",
    "    current_char = 0\n",
    "    current_ent = None\n",
    "    tokens = []\n",
    "    current_token = None\n",
    "    for pw in parsed.words:\n",
    "        # Start of an entity?\n",
    "        if current_char in ents_by_start:\n",
    "            current_ent = ents_by_start[current_char]\n",
    "            current_token = Token(pw, is_compound=True, ent=current_ent)\n",
    "            tokens.append(current_token)\n",
    "        # Inside of entity?\n",
    "        elif current_ent is not None and current_char < current_ent.end_char:\n",
    "            current_token.add_compound_component(pw)\n",
    "        # Normal word\n",
    "        else:\n",
    "            current_ent = None\n",
    "            if pw.upos != 'PUNCT':\n",
    "                tokens.append(Token(pw))\n",
    "        current_char = current_char + len(pw.text) + 1\n",
    "\n",
    "    return ParseTree(nl_sql[\"question\"], nl_sql[\"query\"], tokens, parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Parse Tree for sample sentence (and display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample_tree = generate_parse_tree(data[27])\n",
    "# sample_tree = generate_parse_tree(data[42])\n",
    "print(sample_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Singular/plural handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import inflect\n",
    "\n",
    "inflector = inflect.engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: Replace all table/column names in the parse tree with a placeholder (and add provenance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def replace_table_column_names(db_schema, db_tables, db_columns, db_partial_columns, parse_tree):\n",
    "    \"\"\"\n",
    "    Replace all table/column names in the parse tree with a placeholder (and add provenance)\n",
    "\n",
    "    :param db_schema: db schema\n",
    "    :type db_schema: Dict[str, Any]\n",
    "    :param db_tables: set of table names\n",
    "    :type db_tables: set[str]\n",
    "    :param db_columns: set of column names\n",
    "    :type db_columns: set[str]\n",
    "    :param parse_tree: parse tree\n",
    "    :type parse_tree: ParseTree\n",
    "    \"\"\"\n",
    "    for word in parse_tree.unchanged():\n",
    "        texts = [word.text]\n",
    "        texts_lower = [word.text_lower]\n",
    "\n",
    "        if word.num == Token.NUM_SINGULAR:\n",
    "            plural_text = inflector.plural(word.text)\n",
    "            if plural_text:\n",
    "                texts.append(plural_text)\n",
    "                texts_lower.append(plural_text.lower())\n",
    "        elif word.num == Token.NUM_PLURAL:\n",
    "            singular_text = inflector.singular_noun(word.text)\n",
    "            if singular_text:\n",
    "                texts.append(singular_text)\n",
    "                texts_lower.append(singular_text.lower())\n",
    "\n",
    "        for text, text_lower in zip(texts, texts_lower):\n",
    "            if text != '':\n",
    "                if text in db_columns or text_lower in db_columns:\n",
    "                    word.change(COLUMN_NAME, ChangedBy.DB_COLUMN)\n",
    "                    break\n",
    "                elif text in db_tables or text_lower in db_tables:\n",
    "                    word.change(TABLE_NAME, ChangedBy.DB_TABLE)\n",
    "                    break\n",
    "                elif text in db_partial_columns or text_lower in db_partial_columns:\n",
    "                    word.change(COLUMN_PARTIAL_NAME, ChangedBy.DB_COLUMN)\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: Replace all values in the DB in the parse tree with placeholders (and add provenance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def replace_db_values(db_values, parse_tree):\n",
    "   \"\"\"\n",
    "   Replace all values in the DB in the parse tree with placeholders\n",
    "\n",
    "   :param db_values: set of all values of the database\n",
    "   :type db_values: Set[Any]\n",
    "   :param parse_tree: parse_tree\n",
    "   :type parse_tree: ParseTree\n",
    "   \"\"\"\n",
    "   for word in parse_tree.unchanged():\n",
    "       if word.text in db_values:\n",
    "           word.change(DB_VALUE, ChangedBy.DB_VAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: Replace all Named Entities in the parse tree with placeholders (and add provenance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def replace_named_entities(parse_tree):\n",
    "   \"\"\"\n",
    "\n",
    "   :param parse_tree:\n",
    "   :type parse_tree: ParseTree\n",
    "   \"\"\"\n",
    "   for word in parse_tree.unchanged():\n",
    "       if word.ent is not None and word.ent.type != \"CARDINAL\":\n",
    "           word.change(NAMED_ENTITY, ChangedBy.NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: Replace all numerical values in the parse tree with placeholders (and add provenance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def replace_numerical_values(parse_tree):\n",
    "   \"\"\"\n",
    "   Replace all numerical values in the parse tree with placeholders (and add provenance)\n",
    "\n",
    "   :param parse_tree: parse tree\n",
    "   :type parse_tree: ParseTree\n",
    "   \"\"\"\n",
    "   for word in parse_tree.unchanged():\n",
    "       if word.properties.upos == \"NUM\":\n",
    "           word.change(NUMERICAL, ChangedBy.NUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert placeholders in sample parse tree (and display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(sample_tree)\n",
    "replace_table_column_names(db_schema, db_tables, db_colums, db_partial_columns, sample_tree)\n",
    "replace_db_values(db_values, sample_tree)\n",
    "replace_named_entities(sample_tree)\n",
    "replace_numerical_values(sample_tree)\n",
    "print(sample_tree)\n",
    "print(sample_tree.original_sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve synset(s) for token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Map between stanza and wordnet POS tag format\n",
    "POS_TO_WN_POS = {\"NOUN\": wordnet.NOUN, \"ADJ\": wordnet.ADJ, \"VERB\": wordnet.VERB, \"ADV\": wordnet.ADV}\n",
    "\n",
    "def retrieve_synset(word, pos_tag):\n",
    "    \"\"\"\n",
    "    Get synonym for a given word using WordNet\n",
    "\n",
    "    :param word: word to get synonym for\n",
    "    :type word: str\n",
    "    :param pos_tag: POS tag of given word\n",
    "    :type pos_tag: str\n",
    "    :return: synonym\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    if pos_tag in POS_TO_WN_POS:\n",
    "        containing_synsets = [synset.name().split('.')[0] for synset in wordnet.synsets(word, pos=POS_TO_WN_POS[pos_tag])]\n",
    "        if len(containing_synsets) > 0:\n",
    "            return containing_synsets[0]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: Replace non-placeholder non-stopword tokens in parse tree with corresponding Synset name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def apply_synset_names(parse_tree):\n",
    "    \"\"\"\n",
    "\n",
    "    :param parse_tree:\n",
    "    :type parse_tree: ParseTree\n",
    "    :return:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    for token in parse_tree.unchanged():\n",
    "        if not token.text.lower() in stopwords_en:\n",
    "            synonym = retrieve_synset(token.text, token.properties.upos)\n",
    "            if synonym != token.text:\n",
    "                token.change(synonym, ChangedBy.SYNONYM)\n",
    "    return parse_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply synonym grouping to sample parse tree (and display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "apply_synset_names(sample_tree)\n",
    "print(sample_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Function: Create and process parse tree (incl. provenance) for given NL-SQL pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def parse_nl_sql_pair(nl_sql):\n",
    "   \"\"\"\n",
    "   Create and process parse tree (incl. provenance) for given NL-SQL pair\n",
    "\n",
    "   :param nl_sql: training data entry\n",
    "   :type nl_sql: Dict[Str, Any]\n",
    "   :return: parsed and processed tree\n",
    "   :rtype: ParseTree\n",
    "   \"\"\"\n",
    "   tree = generate_parse_tree(nl_sql)\n",
    "   replace_table_column_names(db_schema, db_tables, db_colums, db_partial_columns, tree)\n",
    "   replace_db_values(db_values, tree)\n",
    "   replace_named_entities(tree)\n",
    "   replace_numerical_values(tree)\n",
    "   apply_synset_names(tree)\n",
    "   return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate trees for every NL-SQL pair in this DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "db_parse_trees = []\n",
    "for nl_sql_pair in data:\n",
    "   db_parse_trees.append(parse_nl_sql_pair(nl_sql_pair))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store string transcoding results in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "patterns = [\n",
    "    {\n",
    "        \"original_nl\": pt.orginal_nl_query,\n",
    "        \"generalized_nl\": str(pt),\n",
    "        \"original_sql\": pt.original_sql_query\n",
    "    } for pt in db_parse_trees]\n",
    "\n",
    "with open(export_trees_file, \"w\") as pattern_file:\n",
    "    json.dump(patterns, pattern_file, indent=4)\n",
    "    print(f\"Generalized {len(patterns)} queries and stored them in '{export_trees_file}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: Compute Parse Tree similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def parse_tree_similarity(source_tree, target_tree):\n",
    "   \"\"\"\n",
    "\n",
    "   :param source_tree:\n",
    "   :type source_tree:\n",
    "   :param target_tree:\n",
    "   :type target_tree:\n",
    "   :return:\n",
    "   :rtype:\n",
    "   \"\"\"\n",
    "   pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: Cluster parse trees using parse tree similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cluster_parse_tree(parse_trees):\n",
    "   \"\"\"\n",
    "\n",
    "   :param parse_trees:\n",
    "   :type parse_trees:\n",
    "   :return:\n",
    "   :rtype:\n",
    "   \"\"\"\n",
    "   pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster all Parse Trees for this DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clusters = cluster_parse_tree(db_parse_trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: Display generic tree and NL-SQL pair for given cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def print_template(tree_cluster):\n",
    "   \"\"\"\n",
    "\n",
    "   :param tree_cluster:\n",
    "   :type tree_cluster:\n",
    "   :return:\n",
    "   :rtype:\n",
    "   \"\"\"\n",
    "   pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Display generic tree and NL-SQL pair for all clusters for this DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for cluster in clusters:\n",
    "   print_template(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
